# -*- coding: utf-8 -*-
"""mnsit_decision_tree

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MtZc30sDaTnweCpy1o5t6vVQwTRAc-FW
"""

import urllib.request
import gzip
import numpy as np
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix

url = 'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz'
filename, headers = urllib.request.urlretrieve(url, 'train-images-idx3-ubyte.gz')
# Load training images
with gzip.open(filename, 'rb') as f:
    data = np.frombuffer(f.read(), np.uint8, offset=16)
    X_train = data.reshape(-1, 28*28)

url = 'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz'
filename, headers = urllib.request.urlretrieve(url, 'train-labels-idx1-ubyte.gz')
# Load training labels
with gzip.open(filename, 'rb') as f:
    data = np.frombuffer(f.read(), np.uint8, offset=8)
    y_train = data

url = 'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz'
filename, headers = urllib.request.urlretrieve(url, 't10k-images-idx3-ubyte.gz')
# Load test images
with gzip.open(filename, 'rb') as f:
    data = np.frombuffer(f.read(), np.uint8, offset=16)
    X_test = data.reshape(-1, 28*28)

url = 'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz'
filename, headers = urllib.request.urlretrieve(url, 't10k-labels-idx1-ubyte.gz')
# Load test labels
with gzip.open(filename, 'rb') as f:
    data = np.frombuffer(f.read(), np.uint8, offset=8)
    y_test = data

print("_____DT on gini_____")

clf = DecisionTreeClassifier(criterion = "gini")
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
print("Accuracy_clf:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred, average='macro'))
print("Recall:", recall_score(y_test, y_pred, average='macro'))
print("F1-score:", f1_score(y_test, y_pred, average='macro'))
print("Confusion matrix:\n", confusion_matrix(y_test, y_pred))

scores = cross_val_score(clf, X_train, y_train, cv=5)
print("Accuracy_cross_train: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))
scores = cross_val_score(clf, X_test, y_test, cv=5)
print("Accuracy_cross_test: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))

param_grid = {
    'max_depth': [5, 10, 15],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 5]
}
grid_search = GridSearchCV(clf, param_grid=param_grid, cv=5)
grid_search.fit(X_train, y_train)
print(grid_search.best_params_)
best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test)
print("Accuracy_grid:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred, average='macro'))
print("Recall:", recall_score(y_test, y_pred, average='macro'))
print("F1-score:", f1_score(y_test, y_pred, average='macro'))
print("Confusion matrix:\n", confusion_matrix(y_test, y_pred))

param_distribs = {
        'max_depth': randint(low=5, high=20),
        'min_samples_split': randint(low=2, high=10),
        'min_samples_leaf': randint(low=1, high=5),
    }
rnd_search = RandomizedSearchCV(clf, param_distributions=param_distribs,
                                n_iter=10, cv=5, random_state=42)
rnd_search.fit(X_train, y_train)
print(rnd_search.best_params_)
best_model = rnd_search.best_estimator_
y_pred = best_model.predict(X_test)
print("Accuracy_rnd_param:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred, average='macro'))
print("Recall:", recall_score(y_test, y_pred, average='macro'))
print("F1-score:", f1_score(y_test, y_pred, average='macro'))
print("Confusion matrix:\n", confusion_matrix(y_test, y_pred))



print("_____DT on entropy_____")


clf = DecisionTreeClassifier(criterion = "entropy")
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
print("Accuracy_clf:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred, average='macro'))
print("Recall:", recall_score(y_test, y_pred, average='macro'))
print("F1-score:", f1_score(y_test, y_pred, average='macro'))
print("Confusion matrix:\n", confusion_matrix(y_test, y_pred))

scores = cross_val_score(clf, X_train, y_train, cv=5)
print("Accuracy_cross_train: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))
scores = cross_val_score(clf, X_test, y_test, cv=5)
print("Accuracy_cross_test: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))

param_grid = {
    'max_depth': [5, 10, 15],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 5]
}
grid_search = GridSearchCV(clf, param_grid=param_grid, cv=5)
grid_search.fit(X_train, y_train)
print(grid_search.best_params_)
best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test)
print("Accuracy_grid:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred, average='macro'))
print("Recall:", recall_score(y_test, y_pred, average='macro'))
print("F1-score:", f1_score(y_test, y_pred, average='macro'))
print("Confusion matrix:\n", confusion_matrix(y_test, y_pred))

param_distribs = {
        'max_depth': randint(low=5, high=20),
        'min_samples_split': randint(low=2, high=10),
        'min_samples_leaf': randint(low=1, high=5),
    }
rnd_search = RandomizedSearchCV(clf, param_distributions=param_distribs,
                                n_iter=10, cv=5, random_state=42)
rnd_search.fit(X_train, y_train)
print(rnd_search.best_params_)
best_model = rnd_search.best_estimator_
y_pred = best_model.predict(X_test)
print("Accuracy_rnd_param:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred, average='macro'))
print("Recall:", recall_score(y_test, y_pred, average='macro'))
print("F1-score:", f1_score(y_test, y_pred, average='macro'))
print("Confusion matrix:\n", confusion_matrix(y_test, y_pred))