# -*- coding: utf-8 -*-
"""mnsit_random_forest

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vRV4a2-W4M_4-grgWd6JXhRGhq9jXOlZ
"""

import urllib.request
import gzip
import numpy as np
from scipy.stats import randint
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

url = 'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz'
filename, headers = urllib.request.urlretrieve(url, 'train-images-idx3-ubyte.gz')
# Load training images
with gzip.open(filename, 'rb') as f:
    data = np.frombuffer(f.read(), np.uint8, offset=16)
    X_train = data.reshape(-1, 28*28)

url = 'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz'
filename, headers = urllib.request.urlretrieve(url, 'train-labels-idx1-ubyte.gz')
# Load training labels
with gzip.open(filename, 'rb') as f:
    data = np.frombuffer(f.read(), np.uint8, offset=8)
    y_train = data

url = 'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz'
filename, headers = urllib.request.urlretrieve(url, 't10k-images-idx3-ubyte.gz')
# Load test images
with gzip.open(filename, 'rb') as f:
    data = np.frombuffer(f.read(), np.uint8, offset=16)
    X_test = data.reshape(-1, 28*28)

url = 'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz'
filename, headers = urllib.request.urlretrieve(url, 't10k-labels-idx1-ubyte.gz')
# Load test labels
with gzip.open(filename, 'rb') as f:
    data = np.frombuffer(f.read(), np.uint8, offset=8)
    y_test = data


print("_RF on gini_")
rf = RandomForestClassifier(criterion='gini', random_state=42)
rf.fit(X_train,y_train)
y_pred = rf.predict(X_test)
print("Accuracy_rf:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred, average='macro'))
print("Recall:", recall_score(y_test, y_pred, average='macro'))
print("F1-score:", f1_score(y_test, y_pred, average='macro'))
print("Confusion matrix:\n", confusion_matrix(y_test, y_pred))

scores = cross_val_score(rf, X_train, y_train, cv=5)
print("Accuracy_cross_on_train: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))
scores = cross_val_score(rf, X_test, y_test, cv=5)
print("Accuracy_cross_test: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))

# Define parameter grid for grid search
param_grid = {
    'n_estimators': [10, 50, 100, 200],
    'max_depth': [10, 50, 100, None],
    'max_features': ['sqrt', 'log2']
}
# Perform grid search using k-fold cross-validation
grid_search = GridSearchCV(rf, param_grid=param_grid, cv=5)
grid_search.fit(X_train, y_train)
print("Best parameters found by grid search:", grid_search.best_params_)
print("Best accuracy score found by grid search:", grid_search.best_score_)
y_pred = grid_search.predict(X_test)
print("Accuracy_grid:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred, average='macro'))
print("Recall:", recall_score(y_test, y_pred, average='macro'))
print("F1-score:", f1_score(y_test, y_pred, average='macro'))
print("Confusion matrix:\n", confusion_matrix(y_test, y_pred))

# Define parameter distribution for randomized search
param_dist = {
    'n_estimators': [10, 50, 100, 200],
    'max_depth': [10, 50, 100, None],
    'max_features': ['sqrt', 'log2']
}
# Perform randomized search using k-fold cross-validation
random_search = RandomizedSearchCV(rf, param_distributions=param_dist, cv=5, n_iter=10)
random_search.fit(X_train, y_train)
print("Best parameters found by randomized search:", random_search.best_params_)
print("Best accuracy score found by randomized search:", random_search.best_score_)
y_pred = random_search.predict(X_test)
print("Accuracy_random:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred, average='macro'))
print("Recall:", recall_score(y_test, y_pred, average='macro'))
print("F1-score:", f1_score(y_test, y_pred, average='macro'))
print("Confusion matrix:\n", confusion_matrix(y_test, y_pred))



print("_RF on entropy_")
rf = RandomForestClassifier(criterion='entropy', random_state=42)
rf.fit(X_train,y_train)
y_pred = rf.predict(X_test)
print("Accuracy_rf:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred, average='macro'))
print("Recall:", recall_score(y_test, y_pred, average='macro'))
print("F1-score:", f1_score(y_test, y_pred, average='macro'))
print("Confusion matrix:\n", confusion_matrix(y_test, y_pred))

scores = cross_val_score(rf, X_train, y_train, cv=5)
print("Accuracy_cross_on_train: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))
scores = cross_val_score(rf, X_test, y_test, cv=5)
print("Accuracy_cross_test: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))

# Define parameter grid for grid search
param_grid = {
    'n_estimators': [10, 50, 100, 200],
    'max_depth': [10, 50, 100, None],
    'max_features': ['sqrt', 'log2']
}
# Perform grid search using k-fold cross-validation
grid_search = GridSearchCV(rf, param_grid=param_grid, cv=5)
grid_search.fit(X_train, y_train)
print("Best parameters found by grid search:", grid_search.best_params_)
print("Best accuracy score found by grid search:", grid_search.best_score_)
y_pred = grid_search.predict(X_test)
print("Accuracy_grid:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred, average='macro'))
print("Recall:", recall_score(y_test, y_pred, average='macro'))
print("F1-score:", f1_score(y_test, y_pred, average='macro'))
print("Confusion matrix:\n", confusion_matrix(y_test, y_pred))

# Define parameter distribution for randomized search
param_dist = {
    'n_estimators': [10, 50, 100, 200],
    'max_depth': [10, 50, 100, None],
    'max_features': ['sqrt', 'log2']
}
# Perform randomized search using k-fold cross-validation
random_search = RandomizedSearchCV(rf, param_distributions=param_dist, cv=5, n_iter=10)
random_search.fit(X_train, y_train)
print("Best parameters found by randomized search:", random_search.best_params_)
print("Best accuracy score found by randomized search:", random_search.best_score_)
y_pred = random_search.predict(X_test)
print("Accuracy_random:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred, average='macro'))
print("Recall:", recall_score(y_test, y_pred, average='macro'))
print("F1-score:", f1_score(y_test, y_pred, average='macro'))
print("Confusion matrix:\n", confusion_matrix(y_test, y_pred))