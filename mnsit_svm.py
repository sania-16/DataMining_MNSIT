# -*- coding: utf-8 -*-
"""mnsit_svm

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HPyc57DaY4Pf8O18Goo9hmrzIL4s0eL6
"""

import urllib.request
import gzip
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
from sklearn.svm import SVC
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import MinMaxScaler
#from sklearn.datasets import fetch_openml

url = 'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz'
filename, headers = urllib.request.urlretrieve(url, 'train-images-idx3-ubyte.gz')
# Load training images
with gzip.open(filename, 'rb') as f:
    data = np.frombuffer(f.read(), np.uint8, offset=16)
    X_train = data.reshape(-1, 28*28)
url = 'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz'
filename, headers = urllib.request.urlretrieve(url, 'train-labels-idx1-ubyte.gz')
# Load training labels
with gzip.open(filename, 'rb') as f:
    data = np.frombuffer(f.read(), np.uint8, offset=8)
    y_train = data
url = 'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz'
filename, headers = urllib.request.urlretrieve(url, 't10k-images-idx3-ubyte.gz')
# Load test images
with gzip.open(filename, 'rb') as f:
    data = np.frombuffer(f.read(), np.uint8, offset=16)
    X_test = data.reshape(-1, 28*28)
url = 'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz'
filename, headers = urllib.request.urlretrieve(url, 't10k-labels-idx1-ubyte.gz')
# Load test labels
with gzip.open(filename, 'rb') as f:
    data = np.frombuffer(f.read(), np.uint8, offset=8)
    y_test = data

scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)

svm_model = SVC()
svm_model.fit(X_train,y_train)
y_pred = svm_model.predict(X_test)
print('Accuracy:', accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred, average='macro'))
print("Recall:", recall_score(y_test, y_pred, average='macro'))
print("F1-score:", f1_score(y_test, y_pred, average='macro'))
print("Confusion matrix:\n", confusion_matrix(y_test, y_pred))


scores = cross_val_score(svm_model, X_train, y_train, cv=5)
print(f"Accuracy_cross: {scores.mean():.2f} +/- {scores.std():.2f}")


"""
param_grid = {'C': [0.1, 1, 10],
              'kernel': ['linear', 'rbf', 'sigmoid'],
              'gamma': [0.01, 0.1, 1]}
svm_grid = GridSearchCV(svm_model, param_grid, cv=5, n_jobs=-1)
svm_grid.fit(X_train, y_train)
print('Best parameters:', svm_grid.best_params_)
y_pred = svm_grid.predict(X_test)
print('Accuracy_grid:', accuracy_score(y_test, y_pred))
svmg=svm_grid.best_estimator_
y_pred =svmg.predict(X_test)
print('Accuracy_grid_best:', accuracy_score(y_test, y_pred))
"""
param_dist = {'C': [0.1, 1, 10],
              'kernel': ['linear', 'rbf'],
              'gamma': [0.01, 0.1, 1]}
svm_random = RandomizedSearchCV(svm_model, param_dist, cv=5, n_jobs=-1)
svm_random.fit(X_train, y_train)
print('Best parameters:', svm_random.best_params_)
y_pred = svm_random.predict(X_test)
print('Accuracy_random:', accuracy_score(y_test, y_pred))
svmr=svm_random.best_estimator_
y_pred =svmr.predict(X_test)
print('Accuracy_random_best:', accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred, average='macro'))
print("Recall:", recall_score(y_test, y_pred, average='macro'))
print("F1-score:", f1_score(y_test, y_pred, average='macro'))
print("Confusion matrix:\n", confusion_matrix(y_test, y_pred))